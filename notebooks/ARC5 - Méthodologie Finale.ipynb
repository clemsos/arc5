{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC5 - Parse data as network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from slugify import slugify\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "data_dir = os.getcwd()\n",
    "\n",
    "fichier_projets = \"../final/ARC5-Final - Projets (tous).csv\"\n",
    "fichier_partenaires = \"../final/ARC5-Final - Partenariats (tous).csv\"\n",
    "fichier_nodes = \"../final/ARC5-Final - Noms (tous).csv\"\n",
    "\n",
    "# parsing helpers\n",
    "project_types = {\n",
    "    \"ADR\" : \"Thèse\",\n",
    "    \"projet\" : \"Projet de recherche\",\n",
    "    \"postdoc\" : \"Recherche post-doctorale\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_slug(name):\n",
    "    return slugify(name.decode('utf-8'))\n",
    "\n",
    "def get_project(name):\n",
    "    slug = get_slug(name)\n",
    "    try :\n",
    "        return G.node[slug]\n",
    "    except KeyError:\n",
    "        n=stored_projects[slug]\n",
    "        print n\n",
    "        node = create_node(n[\"name\"], n[\"type\"], n[\"start\"], n[\"end\"], orga=n[\"orga\"])\n",
    "        print node\n",
    "        return G.node[slug]\n",
    "    \n",
    "def create_node(name, type, start, end, orga=None) : \n",
    "    \n",
    "    slug = get_slug(name)\n",
    "    \n",
    "    try :\n",
    "        if start > G.node[slug][\"start\"] : start =  G.node[slug][\"start\"]\n",
    "        if end > G.node[slug][\"end\"] : start =  G.node[slug][\"end\"]\n",
    "    except:\n",
    "        start = start\n",
    "        endd = end\n",
    "            \n",
    "    node = {}\n",
    "    node[\"id\"] = slug\n",
    "    node[\"type\"] = type\n",
    "    node[\"orga\"] = orga # cluster or ARC ?\n",
    "    node[\"name\"] = name\n",
    "    node[\"start\"] = start\n",
    "    node[\"end\"] = end\n",
    "    \n",
    "    G.add_node(node[\"id\"], node)\n",
    "    return node[\"id\"]\n",
    "\n",
    "# keep data when merging edges\n",
    "def merge_edge_data(Graph, e, data):\n",
    "    \n",
    "    try : \n",
    "        Graph.edge[e[0]][e[1]]\n",
    "    except KeyError:\n",
    "        Graph.add_edge(e[0], e[1])\n",
    "        \n",
    "    try:\n",
    "        Graph.edge[e[0]][e[1]][\"edge_types\"].append(data)\n",
    "    except KeyError:\n",
    "        Graph.edge[e[0]][e[1]][\"edge_types\"] = [data]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../final/ARC5-Final - Noms (tous).csv\n",
      "281 nodes\n",
      "0 edges\n",
      "Counter({'laboratoire': 64, 'm\\xc3\\xa9diation': 51, 'patrimoine': 46, 'localit\\xc3\\xa9': 36, 'creation': 29, 'etablissement': 14, 'enseignement': 11, 'ecole-doctorale': 10, 'cr\\xc3\\xa9ation': 8, '\\xc3\\xa9conomique': 6, 'cst': 6})\n"
     ]
    }
   ],
   "source": [
    "print fichier_nodes\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "with open( os.path.join(data_dir, fichier_nodes), \"r\") as f :\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader :\n",
    "#         print line\n",
    "        start = int(line[\"Début\"])\n",
    "        end =  int(line[\"Fin\"])\n",
    "        node = create_node(line[\"Nom\"], line[\"Type\"], start, end)\n",
    "\n",
    "print \"%s nodes\"%len(G.nodes())\n",
    "print \"%s edges\"%len(G.edges())\n",
    "print Counter([n[1][\"type\"] for n in G.nodes(data=True)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse thèses et projets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../final/ARC5-Final - Projets (tous).csv\n",
      "485 nodes\n",
      "441 edges\n",
      "Counter({'personne': 91, 'projet': 66, 'laboratoire': 64, 'm\\xc3\\xa9diation': 51, 'ADR': 46, 'patrimoine': 46, 'localit\\xc3\\xa9': 36, 'creation': 29, 'etablissement': 14, 'enseignement': 11, 'ecole-doctorale': 10, 'cr\\xc3\\xa9ation': 8, 'cst': 6, '\\xc3\\xa9conomique': 6, 'postdoc': 1})\n",
      "Counter({None: 372, 'ARC5': 113})\n"
     ]
    }
   ],
   "source": [
    "stored_projects={}\n",
    "\n",
    "print fichier_projets\n",
    "\n",
    "# print G.nodes()\n",
    "\n",
    "with open( os.path.join(data_dir, fichier_projets), \"r\") as f :\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader :\n",
    "        \n",
    "        if line[\"Nom Projet\"] and line[\"Orga\"] != \"13\" and line[\"Orga\"] != \"14\":\n",
    "            start = int(line[\"Année\"])\n",
    "            end =  start+3\n",
    "            \n",
    "            # create project\n",
    "            projet = create_node(line[\"Nom Projet\"], line[\"Type\"], start, end, orga=line[\"Orga\"])            \n",
    "\n",
    "            # porteur de projet\n",
    "            porteur = create_node(line[\"Porteurs (nom)\"], \"personne\", start, end)\n",
    "            \n",
    "            # get existing\n",
    "            etablissement = G.node[get_slug(line[\"Etablissement\"])][\"id\"]\n",
    "            laboratoire = G.node[get_slug(line[\"Labo\"])][\"id\"]\n",
    "            \n",
    "            # TODOs : ville !\n",
    "#             ville = G.node[get_slug(line[\"Ville\"], \"localite\")]\n",
    "\n",
    "            edges = []            \n",
    "            edges.append((projet, etablissement))\n",
    "            edges.append((projet, laboratoire))\n",
    "            edges.append((projet, porteur))\n",
    "            edges.append((laboratoire, porteur))\n",
    "            \n",
    "#             edges.append((etablissement, ville))\n",
    "#             edges.append((laboratoire, ville))\n",
    "\n",
    "            for e in edges :\n",
    "                merge_edge_data(G, e, { \"type\" : line[\"Type\"], \"name\" : line[\"Nom Projet\"] })\n",
    "        \n",
    "        elif line[\"Orga\"] == \"13\" or line[\"Orga\"] == \"14\":\n",
    "            start = int(line[\"Année\"])\n",
    "            end =  start+3\n",
    "            stored_projects[get_slug(line[\"Nom Projet\"])] = { \"name\" : line[\"Nom Projet\"], \"type\": line[\"Type\"], \"start\" : start, \"end\" : end, \"orga\" : line[\"Orga\"] }\n",
    "\n",
    "        \n",
    "print \"%s nodes\"%len(G.nodes())\n",
    "print \"%s edges\"%len(G.edges())\n",
    "print Counter([n[1][\"type\"] for n in G.nodes(data=True)]) \n",
    "print Counter([n[1][\"orga\"] for n in G.nodes(data=True)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse partenaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../final/ARC5-Final - Partenariats (tous).csv\n",
      "494 nodes\n",
      "716 edges\n",
      "Counter({'personne': 91, 'projet': 67, 'laboratoire': 64, 'ADR': 54, 'm\\xc3\\xa9diation': 51, 'patrimoine': 46, 'localit\\xc3\\xa9': 36, 'creation': 29, 'etablissement': 14, 'enseignement': 11, 'ecole-doctorale': 10, 'cr\\xc3\\xa9ation': 8, 'cst': 6, '\\xc3\\xa9conomique': 6, 'postdoc': 1})\n"
     ]
    }
   ],
   "source": [
    "print fichier_partenaires\n",
    "\n",
    "with open( os.path.join(data_dir,  fichier_partenaires), \"r\") as f :\n",
    "    reader = csv.DictReader(f) \n",
    "    for i, line in enumerate(reader):\n",
    "        if line[\"Projet\"] and line[\"Structure\"] : \n",
    "\n",
    "            start = int(line[\"début\"])\n",
    "            end =  int(line[\"fin\"])\n",
    "\n",
    "            partenaire = G.node[get_slug(line[\"Structure\"])]\n",
    "\n",
    "    #         TODO : ville\n",
    "    #         ville = create_node(line[\"Ville\"], \"ville\", start, end)\n",
    "\n",
    "            # get project (only those with partners)\n",
    "            projet = get_project(line[\"Projet\"])        \n",
    "\n",
    "            e = (partenaire[\"id\"], projet[\"id\"])\n",
    "            merge_edge_data(G, e, { \"type\" : projet[\"type\"], \"name\" : projet[\"name\"] })\n",
    "\n",
    "print \"%s nodes\"%len(G.nodes())\n",
    "print \"%s edges\"%len(G.edges())\n",
    "print Counter( [n[1][\"type\"] for n in G.nodes(data=True)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert persons to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 494 nodes / 716 edges\n",
      "Counter({2015: 8, 2016: 4, 2017: 2, 2013: 2, 2012: 1})\n",
      "after : 403 nodes / 564 edges\n"
     ]
    }
   ],
   "source": [
    "print \"before : %s nodes / %s edges\"%(len(G.nodes()),len(G.edges()))\n",
    "\n",
    "G_without_people = G.copy()\n",
    "\n",
    "# get all persons in the graph\n",
    "persons = [node[0] for node in G_without_people.nodes(data=True) if node[1][\"type\"] == \"personne\"]\n",
    "# persons_edges = clean_G.edges(persons, data=True)\n",
    "\n",
    "years=[]\n",
    "\n",
    "for person in persons:\n",
    "\n",
    "    # edges for a single person\n",
    "    person_edges = G_without_people.edges(person)\n",
    "  \n",
    "    # get all nodes linked by a single person\n",
    "    list_of_person_nodes = []; map(list_of_person_nodes.extend, map(list,person_edges))\n",
    "    assert len(list_of_person_nodes) == len(person_edges)*2 # make sure we have all nodes\n",
    "    \n",
    "    clean_nodes = [n for n in list_of_person_nodes if n != person]\n",
    "    \n",
    "    #  years += [n[1][\"start\"] for n in clean_nodes]\n",
    "    #  assert len(clean_nodes) == len(person_edges) # make sure we have all new nodes, except the person\n",
    "\n",
    "    if len(person_edges) > 2 : # if have less than degree of 1 then remove node\n",
    "\n",
    "        # get data from the node to add to the edge\n",
    "        data = G_without_people.node[person]\n",
    "        \n",
    "        years.append(data[\"start\"])\n",
    "        \n",
    "        # create new edges between all those\n",
    "        new_edges = list(itertools.combinations(clean_nodes, 2))\n",
    "\n",
    "        # create new edges with merge data info\n",
    "        for e in new_edges:\n",
    "            merge_edge_data(G_without_people, e, { \"type\" : \"personne\", \"name\" : None })\n",
    "\n",
    "    # remove person from the graph\n",
    "    G_without_people.remove_node(person)\n",
    "\n",
    "print Counter(years)\n",
    "print \"after : %s nodes / %s edges\"%(len(G_without_people.nodes()),len(G_without_people.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert projects to edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before : 403 nodes / 564 edges\n",
      "Counter({2013: 36, 2012: 30, 2014: 12, 2015: 9, 2016: 8, 2011: 7, 2010: 1})\n",
      "after : 281 nodes / 1024 edges\n",
      "Counter({'laboratoire': 64, 'm\\xc3\\xa9diation': 51, 'patrimoine': 46, 'localit\\xc3\\xa9': 36, 'creation': 29, 'etablissement': 14, 'enseignement': 11, 'ecole-doctorale': 10, 'cr\\xc3\\xa9ation': 8, 'cst': 6, '\\xc3\\xa9conomique': 6})\n"
     ]
    }
   ],
   "source": [
    "print \"before : %s nodes / %s edges\"%(len(G_without_people.nodes()),len(G_without_people.edges()))\n",
    "\n",
    "G_without_people_and_projects = G_without_people.copy()\n",
    "\n",
    "# get all projects in the graph\n",
    "projects = [node[0] for node in G_without_people_and_projects.nodes(data=True) if node[1][\"type\"] == \"projet\" or node[1][\"type\"] == \"ADR\" or node[1][\"type\"] == \"postdoc\" ]\n",
    "\n",
    "years = []\n",
    "\n",
    "for project in projects:\n",
    "\n",
    "    # edges for a single person\n",
    "    project_edges = G_without_people_and_projects.edges(project)\n",
    "  \n",
    "    # get all nodes linked by a single person\n",
    "    list_of_project_nodes = []; map(list_of_project_nodes.extend, map(list, project_edges))\n",
    "    assert len(list_of_project_nodes) == len(project_edges)*2 # make sure we have all nodes\n",
    "    \n",
    "    clean_nodes = [n for n in list_of_project_nodes if n != project]\n",
    "#     assert len(clean_nodes) == len(person_edges) # make sure we have all new nodes, except the person\n",
    "\n",
    "    if len(project_edges) > 2 : # if have less than degree of 1 then remove node\n",
    "\n",
    "        # get data from the node to add to the edge\n",
    "        data = G_without_people_and_projects.node[project]\n",
    "        \n",
    "        years.append(data[\"start\"])\n",
    "\n",
    "        # create new edges between all those\n",
    "        new_edges = list(itertools.combinations(clean_nodes, 2))\n",
    "                \n",
    "        # parse text properly\n",
    "        \n",
    "        # merge data into edge info\n",
    "        for e in new_edges:\n",
    "            \n",
    "            proj=G.node[project]\n",
    "            txt = { \"type\" : proj[\"type\"], \"name\" : proj[\"name\"]}\n",
    "            \n",
    "            merge_edge_data(G_without_people_and_projects, e, txt) \n",
    "#             G_without_people_and_projects.add_edge( e[0], e[1], {\"type\" : \"projet\", \"additionalInfo\" : data} )\n",
    "\n",
    "    # remove person from the graph\n",
    "    G_without_people_and_projects.remove_node(project)\n",
    "\n",
    "\n",
    "print Counter(years)\n",
    "\n",
    "print \"after : %s nodes / %s edges\"%(len(G_without_people_and_projects.nodes()),len(G_without_people_and_projects.edges()))\n",
    "print Counter([ c[1][\"type\"] for c in G_without_people_and_projects.nodes(data=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse final graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 nodes\n",
      "1024 edges\n"
     ]
    }
   ],
   "source": [
    "# create the graph\n",
    "\n",
    "nodes = []\n",
    "for n in G_without_people_and_projects.nodes(data=True): \n",
    "    \n",
    "    # ignore singletons\n",
    "    if G_without_people_and_projects.degree(n[0]) > 0:\n",
    "        node = n[1]\n",
    "        node[\"id\"] = n[0]\n",
    "        node[\"group\"] = n[1][\"type\"]\n",
    "        nodes.append(node)\n",
    "\n",
    "print \"%s nodes\"%len(nodes)\n",
    "        \n",
    "edges = []\n",
    "for i, e in enumerate(G_without_people_and_projects.edges(data=True)): \n",
    "    \n",
    "    edge = e[2]\n",
    "    \n",
    "    # calculate edge weight\n",
    "    edge[\"weight\"] = len(edge[\"edge_types\"])\n",
    "        \n",
    "    notes = \"\"\n",
    "    team = 0\n",
    "    \n",
    "    for t in edge[\"edge_types\"]:\n",
    "        if t[\"type\"] == \"ADR\" or t[\"type\"] == \"projet\" or t[\"type\"] == \"postdoc\" : \n",
    "            notes = notes  + \"* %s : %s \\n\"%(project_types[t[\"type\"]], t[\"name\"])\n",
    "        elif t[\"type\"] == \"personne\":\n",
    "            team = team + 1\n",
    "    \n",
    "    if team != 0 : \n",
    "        notes = \"* Membres d'équipe en commun \\n\" + notes\n",
    "    \n",
    "    edge[\"additionalInfo\"] = notes    \n",
    "    \n",
    "    edge[\"source\"] = e[0]\n",
    "    edge[\"target\"] = e[1]\n",
    "    \n",
    "    edges.append(edge)\n",
    "\n",
    "print \"%s edges\"%len(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the final graph on Topogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<topogram_client.TopogramAPIClient object at 0x7f3ddf79ae90>\n",
      "{u'status': u'error', 'status_code': 200, u'message': u'A topogram with the same name already exists', u'data': [{u'sharedPublic': True, u'name': u'ARC 5 - Collaborations Culture / Recherche en Rh\\xf4ne-Alpes', u'owner': u'FWGtG3EXa2F7nZRKp', u'_id': u'3Fep7oZAFjqBnHLQR', u'slug': u'arc-5-collaborations-culture-recherche-en-rhne-alpes', u'createdAt': u'2016-09-12T04:25:24.618Z'}]}\n",
      "876 existing edges, 197 existing nodes\n",
      "nodes deleted\n",
      "edges deleted\n",
      "212 nodes created.\n",
      "1024 edges created.\n",
      "done. Topogram is online at https://app.topogram.io/topograms/3Fep7oZAFjqBnHLQR/view\n"
     ]
    }
   ],
   "source": [
    "from topogram_client import TopogramAPIClient\n",
    "import logging \n",
    "import datetime\n",
    "\n",
    "now=datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "# passwords\n",
    "TOPOGRAM_URL = \"https://app.topogram.io\" # \"http://localhost:3000\" \n",
    "USER = \"arc5@arc5.com\"\n",
    "PASSWORD = \"culture&recherche\"\n",
    "\n",
    "# connect to the topogram instance \n",
    "topogram = TopogramAPIClient(TOPOGRAM_URL)\n",
    "\n",
    "# topogram.create_user(USER, PASSWORD)\n",
    "topogram.user_login(USER, PASSWORD)\n",
    "print topogram\n",
    "\n",
    "r = topogram.create_topogram(\"ARC 5 - Collaborations Culture / Recherche en Rhône-Alpes\")\n",
    "print r\n",
    "topogram_ID = r[\"data\"][0][\"_id\"]\n",
    "\n",
    "# get and backup existing nodes and edges\n",
    "existing_nodes = topogram.get_nodes(topogram_ID)[\"data\"]\n",
    "url = slugify(TOPOGRAM_URL.decode('utf-8'))\n",
    "with open('data/ARC5-%s-nodes-%s.json'%(url,now), 'w') as outfile:\n",
    "    json.dump(existing_nodes, outfile)\n",
    "\n",
    "existing_edges = topogram.get_edges(topogram_ID)[\"data\"]\n",
    "with open('data/ARC5-%s-edges-%s.json'%(url,now), 'w') as outfile:\n",
    "    json.dump(existing_edges, outfile)\n",
    "\n",
    "print \"%s existing edges, %s existing nodes\"%(len(existing_edges), len(existing_nodes))\n",
    "\n",
    "# clear existing graph\n",
    "topogram.delete_nodes([n[\"_id\"] for n in existing_nodes])\n",
    "print \"nodes deleted\"\n",
    "topogram.delete_edges([n[\"_id\"] for n in existing_edges])\n",
    "print \"edges deleted\"\n",
    "\n",
    "r = topogram.create_nodes(topogram_ID, nodes)\n",
    "print \"%s nodes created.\"%len(r[\"data\"])\n",
    "r = topogram.create_edges(topogram_ID, edges)\n",
    "print \"%s edges created.\"%len(r[\"data\"])\n",
    "\n",
    "print \"done. Topogram is online at %s/topograms/%s/view\"%(TOPOGRAM_URL, topogram_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save to File\n",
    "\n",
    "with open('../final/ARC5-nodes.json', 'w') as outfile:\n",
    "    json.dump(nodes, outfile)\n",
    "\n",
    "existing_edges = topogram.get_edges(topogram_ID)[\"data\"]\n",
    "with open('../final/ARC5-edges.json', 'w') as outfile:\n",
    "    json.dump(edges, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "MarkdownCell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
